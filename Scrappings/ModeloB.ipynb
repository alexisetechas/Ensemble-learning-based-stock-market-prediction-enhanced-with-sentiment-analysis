{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba60f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-bcb pandas seaborn sklearn yfinance xgboost optuna scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccfba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from bcb import sgs\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_INICIAL = '2019-04-09'\n",
    "DATA_FIM = '2025-10-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['^GSPC', '^VIX', '^TNX',  'BZ=F', 'BRL=X', 'IRFM11.SA']\n",
    "dataframes = []\n",
    "closes = []\n",
    "for ticker in tickers:\n",
    "    dado = yf.download(\n",
    "        ticker,\n",
    "        start= DATA_INICIAL,\n",
    "        end= DATA_FIM,\n",
    "        auto_adjust=True\n",
    "    )\n",
    "\n",
    "    if not dado.empty:\n",
    "        close = dado[['Close']].rename(columns={'Close': ticker})\n",
    "        closes.append(close)\n",
    "df_final = pd.concat(closes, axis=1)\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipca_exp = sgs.get(433, start=DATA_INICIAL, end=DATA_FIM)\n",
    "ipca_exp.rename(columns={433: 'IPCA_Expectativa_12m'}, inplace=True)\n",
    "\n",
    "selic = sgs.get(432, start=DATA_INICIAL, end=DATA_FIM)\n",
    "selic.rename(columns={432: 'Selic_Meta'}, inplace=True)\n",
    "\n",
    "ibcbr = sgs.get(24363, start=DATA_INICIAL, end=DATA_FIM)\n",
    "ibcbr.rename(columns={24363: 'IBC_Br'}, inplace=True)\n",
    "\n",
    "ptax = sgs.get(1, start=DATA_INICIAL, end=DATA_FIM)\n",
    "ptax.rename(columns={1: 'Dolar_PTAX'}, inplace=True)\n",
    "\n",
    "macro_bcb = {\n",
    "    'IPCA_EXP': ipca_exp,\n",
    "    'SELIC': selic,\n",
    "    'IBC_BR': ibcbr,\n",
    "    'PTAX': ptax\n",
    "}\n",
    "macro_bcb['SELIC'].describe()\n",
    "\n",
    "macro_df = pd.concat(macro_bcb.values(), axis=1)\n",
    "macro_df.head()\n",
    "macro_df = macro_df.ffill()\n",
    "macro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48183a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "join = [macro_df, df_final]\n",
    "\n",
    "externo = pd.concat(join, axis=1)\n",
    "print(externo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34311160",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_focus = (\n",
    "    \"https://olinda.bcb.gov.br/olinda/servico/Expectativas/versao/v1/odata/\"\n",
    "    \"ExpectativasMercadoAnuais?$top=100000\"\n",
    "    \"&$filter=Indicador%20eq%20'IPCA'%20and%20Data%20ge%20'2019-04-09'\"\n",
    "    \"&$format=json\"\n",
    "    \"&$orderby=Data%20asc\"\n",
    ")\n",
    "try:\n",
    "    json = pd.read_json(url_focus)\n",
    "    Focus = pd.DataFrame(json['value'].tolist())\n",
    "\n",
    "    Focus['Data'] = pd.to_datetime(Focus['Data'])\n",
    "\n",
    "    Focus['DataReferencia'] = Focus['DataReferencia'].astype(int)\n",
    "    \n",
    "    Focus['Ano_Divulgacao'] = Focus['Data'].dt.year\n",
    "    \n",
    "    Focus = Focus[Focus['DataReferencia'] == Focus['Ano_Divulgacao']].copy()\n",
    "\n",
    "    Focus = Focus.set_index('Data').sort_index()\n",
    "    \n",
    "    Focus = Focus[['Mediana']].rename(columns={'Mediana': 'IPCA_Expectativa_AnoCorrente'})\n",
    "    \n",
    "    print(Focus.tail())\n",
    "\n",
    "except Exception as e:\n",
    "    raise TypeError\n",
    "print(Focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391809da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Focus = Focus.groupby(Focus.index).mean()\n",
    "Focus = Focus.sort_index()\n",
    "print(Focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureBase = pd.merge(externo, Focus, left_index=True, right_index=True, how='inner')\n",
    "FeatureSemanal = FeatureBase[FeatureBase.index.dayofweek == 4].copy()\n",
    "print(FeatureSemanal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert = pd.read_csv('FinBert.csv')\n",
    "finbert['data'] = pd.to_datetime(finbert['data'])\n",
    "\n",
    "Diario = finbert.groupby('data')['score'].sum().sort_index()\n",
    "Diario = Diario.to_frame(name='scoreTotal')\n",
    "\n",
    "Diario['scoreSemanal'] = Diario['scoreTotal'].rolling('7D', min_periods=1).mean()\n",
    "\n",
    "FeatureB = Diario.loc[Diario.index.dayofweek == 4, ['scoreSemanal']].copy()\n",
    "\n",
    "print(FeatureB.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59682b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_B = pd.merge(FeatureB, FeatureSemanal, left_index=True, right_index=True, how='inner')\n",
    "print(Features_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e0bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = Features_B.isna().sum()\n",
    "print(nans[nans > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c049347",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_B = Features_B.ffill()\n",
    "Features_B = Features_B.dropna()\n",
    "\n",
    "print(f\"Total de NaNs: {Features_B.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f35660",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_B.columns\n",
    "\n",
    "Features_B.columns = [\n",
    "    'scoreSemanal',\n",
    "    'ipcaMensal',\n",
    "    'selicMeta',\n",
    "    'ibcBrActivity',\n",
    "    'dolarPtax',\n",
    "    'sp500Index',\n",
    "    'vixIndex',\n",
    "    'treasuryYield10y',\n",
    "    'brentOilPrice',\n",
    "    'usdBrlExchange',\n",
    "    'irfm11FixedIncome',\n",
    "    'IPCA_Ano_Atual'\n",
    "]\n",
    "\n",
    "Features_B.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac755e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Features_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a95aa",
   "metadata": {},
   "source": [
    "Pre-processamento antes do XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02bcbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "padrao = pd.read_csv('./dados/BaseA.csv')\n",
    "padrao['Data'] = pd.to_datetime(padrao['Data'])\n",
    "alinhamento = padrao['Data'].values\n",
    "\n",
    "if not isinstance(Features_B.index, pd.DatetimeIndex):\n",
    "    Features_B.index = pd.to_datetime(Features_B.index)\n",
    "\n",
    "Features_B = Features_B.ffill()\n",
    "Features_B = Features_B.dropna()\n",
    "\n",
    "ativos = pd.read_csv('ibovespa.csv', sep=';')\n",
    "dataset = {}\n",
    "tickers = ativos['ticker']\n",
    "\n",
    "print(f\"Iniciando processamento para {len(tickers)} ativos...\")\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        df = yf.download(\n",
    "            ticker,\n",
    "            start=DATA_INICIAL,\n",
    "            end=DATA_FIM,\n",
    "            auto_adjust=True,\n",
    "            progress=False\n",
    "        )\n",
    "        \n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "        df = df[df.index.weekday == 4]\n",
    "\n",
    "        var = pd.merge(df, Features_B, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "        var['AlvoRetorno'] = var['Close'].shift(-1) / var['Close'] - 1\n",
    "        var['Alvo'] = np.where(var['AlvoRetorno'] > 0, 1, 0)\n",
    "\n",
    "        var = var.drop(columns=['Open', 'High', 'Low', 'Close', 'Volume'], errors='ignore')\n",
    "        \n",
    "        var = var.dropna(subset=['Alvo', 'AlvoRetorno'])\n",
    "        var['Alvo'] = var['Alvo'].astype(int)\n",
    "\n",
    "        var_final = var[var.index.isin(alinhamento)].copy()\n",
    "\n",
    "        if not var_final.empty:\n",
    "            dataset[ticker] = var_final\n",
    "            \n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c65921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ref = pd.read_csv('./dados/Interseccao.csv')\n",
    "DatasEmp = pd.to_datetime(ref['Data']).values\n",
    "\n",
    "if ticker in dataset:\n",
    "    dataset[ticker] = dataset[ticker][dataset[ticker].index.isin(DatasEmp)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b67723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for tick, df in dataset.items():\n",
    "    featuresCol = [c for c in df.columns if c not in ['Alvo', 'AlvoRetorno','scoreSemanal']]\n",
    "    \n",
    "    x = df[featuresCol]\n",
    "    \n",
    "    corr_matrix = x.corr().abs()\n",
    "\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "    if len(drop) > 0:\n",
    "        print(f\"[{tick}] Removendo {len(drop)} features redundantes: {drop}\")\n",
    "        \n",
    "        dataset[tick] = df.drop(columns=drop)\n",
    "print(\"\\nTratamento de correlação concluido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c7ea3",
   "metadata": {},
   "source": [
    "Teste de datas iguais em ambos os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['PETR4.SA'].tail(-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "modelos = {}\n",
    "\n",
    "for ticker, df in dataset.items():\n",
    "    print(f\"\\n--- Treinando: {ticker} ---\")\n",
    "    \n",
    "    features = [c for c in df.columns if c not in ['Alvo', 'AlvoRetorno']]\n",
    "    X = df[features]\n",
    "    y = df['Alvo']\n",
    "\n",
    "    split = int(len(df) * 0.8)\n",
    "    \n",
    "    X_dev = X.iloc[:split]\n",
    "    y_dev = y.iloc[:split]\n",
    "    \n",
    "    X_backtest = X.iloc[split:]\n",
    "    y_backtest = y.iloc[split:]\n",
    "    \n",
    "    def objective(trial):\n",
    "\n",
    "        cutoff = int(len(X_dev) * 0.75)\n",
    "        X_train_opt, X_val_opt = X_dev.iloc[:cutoff], X_dev.iloc[cutoff:]\n",
    "        y_train_opt, y_val_opt = y_dev.iloc[:cutoff], y_dev.iloc[cutoff:]\n",
    "        \n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_train_opt, y_train_opt)\n",
    "        \n",
    "        preds = model.predict(X_val_opt)\n",
    "        \n",
    "        score = precision_score(y_val_opt, preds, zero_division=0)\n",
    "        \n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    study.optimize(objective, n_trials=100) \n",
    "    \n",
    "    print(f\"Melhor Score: {study.best_value:.2%}\")\n",
    "    print(f\"Melhores Parâmetros: {study.best_params}\")\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params['random_state'] = 42\n",
    "    best_params['n_jobs'] = -1\n",
    "    \n",
    "    final_model = xgb.XGBClassifier(**best_params)\n",
    "    final_model.fit(X_dev, y_dev)\n",
    "    \n",
    "    modelos[ticker] = final_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
